---
title: "Lineær Regresjon. Digital samling 1"
author: "Njål Foldnes"
footer:  "[hjem](https://njaalf.github.io/MPS-140/)"
   
format: 
  revealjs: 
    multiplex: true
    transition: fade
    slide-number: true
editor: visual
execute:
  echo: false
  message: false
  warning: false
---

```{r, echo=F, message=F, warning=FALSE}
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
library(kableExtra)
library(broom)
library(modelsummary)
library("pwr")
library("see")
library("performance")
library("report")
library("tidyverse")
theme_set(theme_minimal())
# pinfo <- read_csv("../data/participant_info.csv")
# wellbeing <- read_csv("../data/wellbeing.csv")
# screen <- read_csv("../data/screen_time.csv")
# 
# wemwbs <- wellbeing %>%
#   pivot_longer(names_to = "var", values_to = "score", -Serial) %>%
#   group_by(Serial) %>%
#   summarise(tot_wellbeing = sum(score))
# 
# screen_long <- screen %>%
#   pivot_longer(names_to = "var", values_to = "hours", -Serial) %>%
#   separate(var, c("variable", "day"), "_")
# screen2 <- screen_long %>%
#   mutate(variable = dplyr::recode(variable,
#                "Watch" = "Watching TV",
#                "Comp" = "Playing Video Games",
#                "Comph" = "Using Computers",
#                "Smart" = "Using Smartphone"),
#      day = dplyr::recode(day,
#               "wk" = "Weekday",
#               "we" = "Weekend"))
# dat_means <- inner_join(wemwbs, screen2, "Serial") %>%
#   group_by(variable, day, hours) %>%
#   summarise(mean_wellbeing = mean(tot_wellbeing))
# ggplot(dat_means, aes(hours, mean_wellbeing, linetype = day)) +
#   geom_line() +
#   geom_point() +
#   facet_wrap(~variable, nrow = 2)
# 
# smarttot <- screen2 %>%
#   filter(variable == "Using Smartphone") %>%
#   group_by(Serial) %>%
#   summarise(tothours = mean(hours))
# smart_wb <- smarttot %>%
#   filter(tothours > 1) %>%
#   inner_join(wemwbs, "Serial") %>%
#   inner_join(pinfo, "Serial") 
# 
# smart_wb <- smart_wb %>%
#   mutate(thours_c = tothours - mean(tothours),
#          male_c = ifelse(male == 1, .5, -.5),
#          male_c = as.factor(male_c),
#          male = as.factor(male))
# saveRDS(smart_wb, "smartphone_wellbeing.rds")



```

# Et lite eksempel for enkel regresjon

## Lekeeksempel

::: {layout-ncol="1"}
![](tabell.png){width="400"}

![](scatterreg.png){width="400"}
:::

## Estimere modellen med $\textsf{lm()}$ og plotte

```{r, echo=T}
x <- c(-5, 10, 15, 31, 42)
y <- c(3,3,0,1, -1)
model <- lm(y~x)
qplot(x,y)+geom_smooth(method="lm", se=F)
```

## Utskrift fra $\textsf{lm()}$

```{r, echo=T}
summary(model)
```

## $R^2$: forklart varians

-   Residualet: Avstand fra den faktiske $y$ verdien til den $y$ som modellen predikerer (på linja)

-   $R^2$: Andel av variasjonen i $y$ som kan forklares av $x$ (to versjoner). Jo høyere, jo bedre er linja som forklaringsmodell

## Predikere nye verdier

Dersom vi har en ny verdie, $x=20$ kan vi bruke linja til en kvalifisert gjetning på hva $y$ vil være:

```{r, echo=T}
yhat <- predict(model, newdata=data.frame(x=20))
yhat
qplot(x,y, size=3)+geom_smooth(method="lm", se=F)+geom_point(aes(x=20, y=yhat),size=5, color="red")
```

## Enkel regresjon

Vi ønsker å studere en kontinuerlig variabel $y$. Denne kalles den *avhengige* variabelen.

Vi forklarer variasjonen i $y$ ved hjelp av en enkel forklaringsvariabel $x$ og en *lineær* sammenheng

$$ y = \beta_0+ \beta_1 x + \epsilon$$

-   $\beta_1 > 0$: positiv sammenheng mellom $x$ og $y$
-   $\beta_1 < 0$: negativ sammenheng mellom $x$ og $y$
-   $\beta_1 = 0$: ingen sammenheng mellom $x$ og $y$

## Antagelser i lineær regresjon

-   Linearitet!
-   Homoskedastisitet: Residualene må ha samme varians uansett hva $x$ er. Kan sjekkes med å plotte residualene vs de predikerte (fitted values)
-   Hvis det er et lite utvalg så bør residualene være normalfordelte

## OK: lineært og homoskedastisk

![Perfekt](perfekt.png)

## IKKE OK: ikke lineært!

![Sammenhengen er ikke lineær](nonlinear.png)

Kan fikses ved å ta med $x^2$ som uavhengig variabel

## IKKE OK: homoskedastiske feilledd

![Residualene varierer mer jo større $x$ er](hetero.png)

Kan fikses ved å bruke en robust estimator av White-typen

# Reelt datasett: Trivsel og mobilbruk blant engelske 15 åringer

## Trivsel og sosiale medier engelske 15 åringer

Przybylski, A. & Weinstein, N. (2017). A Large-Scale Test of the Goldilocks Hypothesis. *Psychological Science*, *28*, 204--215.

Storskala studie som finner støtte til "Goldilocks" hypotesen.

Dataene er tilgjengelige [her](https://osf.io/49rmq/files/osfstorage)

Se også "smartphone_wellbeing.rds" filen i Data folderen på kurssiden.




## Trivsel - Wellbeing

Vi ønsker å studere trivsel. Det er vår *avhengige* variabel:

Trivsel målt med [Warwick-Edinburgh Mental Well-Being Scale (WEMWBS)](https://warwick.ac.uk/fac/med/research/platform/wemwbs/). Spørreskjema med 14 *items* og 5 responsnivå. Vi bruker summescoren

```{r}
populasjon <- readRDS("../data/smartphone_wellbeing.rds")#last inn data
hist(populasjon$tot_wellbeing)#histogram
hist(populasjon$tothours)
```

Vi har `r nrow(populasjon)` deltagere! La oss tenke på dette som POPULASJONEN

## Negativ trivsel og telefonbruk i "populasjonen"

```{r, echo=T}
popmodel <- lm(tot_wellbeing~ tothours, data=populasjon)
popmodel %>% tidy() %>% kable(digits=2)
```

En time ekstra daglig mobilbruk gir en forventet nedgang i trivsel på 0.81

## Sammenheng trivsel og telefonbruk i et tilfeldig utvalg av 400 15-åringer

```{r}
set.seed(1)
utvalgte <- sample(1:nrow(populasjon),400)# tilfeldig utvalg av 500
utvalg <- populasjon[utvalgte, ]
utvalg <- readRDS("../data/goldilocksutvalg.rds")
ggplot(utvalg, aes(tothours, tot_wellbeing))+geom_jitter(height=0) +geom_smooth(method="lm", se=F)+xlab("Antall timer daglig")+ylab("Total trivsel")
```

## Regresjon i utvalget

```{r}
model <- lm(tot_wellbeing~ tothours, data=utvalg)
model %>% tidy() %>% kable(digits=2)
```

Ganske likt populasjonsverdiene! Vi har linearitet.

## Homoskedastiske feilledd?

```{r}
ggplot(model, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0)
```

Her har vi tilnærmet homoskedastisitet!

## Husk at estimatene er usikre!

Her er fire andre utvalg av størrelse $n=400$. Vi ser at intercept og slope varierer endel!

```{r}
library(ggpmisc)
num <- 4
set.seed(2)
df <-  sample(1:nrow(populasjon),num*400)
df <- populasjon[df, ]
df$utvalg <- rep(1:num, 400)
ggplot(data = df, aes(tothours, tot_wellbeing)) +
  stat_poly_line(se=F) +
  stat_poly_eq(use_label(c("eq"))) +
  geom_point(alpha=.1)+facet_wrap(utvalg~.)
```

# Multippel regresjon

## Multippel regresjon

En enkel uvidelse av enkel regresjon, der vi har flere *uavhengige* variable

$$ y = \beta_0+ \beta_1 x_1 +  \beta_2 x_2+ \beta_3 x_3+ \epsilon$$ Her har vi TRE forklaringsvariabler $x_1,x_2, x_3$ som forklarer hvorfor $y$ varierer!

## Ceteris paribus

Ceteris paribus \[keːˈtɛ.riːsˈpa.rɪ.bʊs\] latinsk for "alt annet likt"

I multippel regresjon får vi effekten av en variabel på $y$, "alt annet likt". Vi *kontrollerer* for de andre variablene!

For eksempel: $$ y = 1+ 2 \cdot x_1 - x_2+ 0.5 \cdot x_3+ \epsilon$$ Når $x_1$ øker med 1 enhet, så øker $y$ med 2 enheter, *alt annet likt*. Dvs at vi holder $x_2$ og $x_3$ fast, og får isolert sammenhengen mellom $x_1$ og $y$.

## Eksempel: Effekt av telefonbruk på Well-being, kontrollert for kjønn

Gutter har høyere trivsel (6.5 poeng) og lavere mobilforbruk:

```{r, echo=T}
utvalg %>% group_by(male) %>%
  summarise(wbsnitt=mean(tot_wellbeing),
            tothoursnitt=mean(tothours))
```

Vi tar med kjønn som forklaringsvariabel. Dette er en kategorisk variabel, vi koder den med en *dummy* variabel: male=0 betyr jente, male=1 betyr gutt.

## Kategoriske variabler og dummy-koding

kategoriske variabler kan kodes med dummyvariabler i regresjon. Dersom vi har $K$ kategorier, trenger vi $K-1$ dummy variabler:

-   Kjønn: $K=2$. Vi har $K-1=2-1=1$ dummy variabel.
-   USA politisk tilørighet: Dem, Rep, Ind: $K=3$. Vi har $K-1=2-1=2$ dummy variabler. For eksempel kan vi har $R=1$ hvis republikaner, og $D=1$ hvis demokrat. Vi trenger ikke $Ind$, siden dersom $R=0$ og $D=0$ så vet vi at det er en independent velger.

## Multippel regresjon i R

$$ \text{tot_wellbeing} = \beta_0+ \beta_1 \cdot \text{tothours}+ \beta_2 \cdot \text{male}+\epsilon$$

```{r, echo=T}
multmodel <- lm(tot_wellbeing~ tothours+male, data=utvalg)
multmodel %>% tidy() %>% kable(digits=2)
```

## Telefonbruk, kjønn og well-being

```{r}
multmodel %>% tidy() %>% kable(digits=2)
```

Effekten av telefonbruk er litt mindre når vi kontrollerer for kjønn (-0.934 $\rightarrow$ -0.688 )

Og effekt av kjønn på trivsel, *når vi kontrollerer for telefonbruk*, er lavere nå, 6.07. Så noe av den observerte trivselforskjellen på 6.5 kan forklares ved at guttene er mindre på mobil, og at mobil ikke er bra for wellbeing!

# ANOVA

## ANOVA analysis of variance

I intro statistikk så lærer man anova. - Du har flere grupper i populasjonen - Du lurer på om $y$ har samme gjennomsnitt i alle gruppene - $H_0:\mu_1=\mu_2=\cdots=\mu_g$ - Alternativhypotesen er at gruppegjennomsnittene ikke alle er like!

## Eksempel

Vi antar at i utvalget var det 4 skoler. Vi ønsker å teste om well-being er den samme på alle skolene:

```{r, echo=T}
aov(tot_wellbeing~ school, utvalg) %>% tidy() %>% kable(digits=2) 
```

Vi har ikke støtte for å hevde at det er forskjell i well-being mellom de 4 skolene (p-verdi=.77 vi beholder $H_0$)
